<!-- # Интеллектуальный анализ данных -->
## Задание 3
Изучение модели классификации **Decision Tree** (дерево принятия решения) и ее применение к тестовому набору данных.

Процесс, демонстрирующий работу модели Decision Tree и ее применения к тестовому набору данных, загружается следующим образом:
Open -> Samples -> processes -> 01_Learner -> 11_ModelApplier

Необходимо изучить работу данной модели, соединив надлежащим образом входы и выходы блоков процесса.

Итогом работы должен быть отчет, содержащий:

1. Скриншот схемы процесса, содержащий основные блоки и их соединения.
2. Описание исходного набора данных для обучения - закладка ExampleSet (Retrieve) -> DataView 
3. Описание исходного набора данных для применения модели - закладка ExampleSet (Retrieve (2)) -> DataView 
4. Анализ результата применения модели классификации к тестовому набору данных.

## Отчет
### 1. Основные блоки и соединения
![1](https://user-images.githubusercontent.com/5549677/34783493-c6aad524-f63c-11e7-8e9c-22fb2c27bc48.png)

#### Основные параметры модели Decision Tree
- `criterion` - критерий по которому будет происходить разделение дерева на 2 ветви.
- `maximal depth` - максимальная глубина дерева (длина от корня до листьев)
- `apply pruning` - обрезание дерева после его полного построения
    - `confidence` - уверенность уверенности, используемый для вычисления ошибки пранинга
- `apply prepruning` - обрезание дерева по ходу построения на основе доп параметров (используются как критерий остановки):
    - `minimal gain ` - минимальное усиление, узел разделяется если его усиление больше чем минимальное усиление. Чем больше это значение тем меньше будет ветвлений и тем меньше дерево. Очень большое значение приведет к дереву с одним узлом.
    - `minimal leaf size` - минимальное количество примеров в каждом листе
    - `minimal size for split` - разделяются только те узлы, размер которых больше либо равен `minimal size for split`
    - `number of prepruning alternatives` - когда разделение прерывается из-за `prepruning` на определенном узле, этот параметр определяет число альтернативных узлов которые нужно протестировать для разделения

### 2. Набор данных для обучения (train)
Исходный набор данных содержит информацию о работе гольф-клуба. Каждая строка таблицы это рабочий день гольф-клуба таблица содержит информацию о:
- была ли игра или нет
- погода
- температура
- влажность
- наличие ветра

![2](https://user-images.githubusercontent.com/5549677/34783903-d6432c74-f63d-11e7-9084-0e376f734d98.png)

### 3. Набор данных для применения модели (test)
Таблица набора данных для применения модели содержит те же поля что и обучающая таблица. При этом дни не пересекаются с обучающей таблицей.

![3](https://user-images.githubusercontent.com/5549677/34783904-d672cf38-f63d-11e7-99f4-54db2a0a0ff5.png)

### 4. Анализ результата применения модели классификации к тестовому набору данных
Результатом применения модели является дерево решений. Решается задача классификации. Листья дерева - это либо `yes` либо `no` (играть или не играть). Первый и внутренние узлы дерева - это проверки различных полей исходных данных. (`какая погода?`, `есть ли ветер?` итд)

Модель дерева решений позволяет предсказать владельцу гольф-клуба будет ли игра или нет в конкретный день, на основе записей о прошлых играх.

![4](https://user-images.githubusercontent.com/5549677/34783906-d6acef24-f63d-11e7-809a-80042e344046.png)

Рассмотрим как ведет себя модель в зависимости от разных параметров. На значениях по умолчанию
```
criterion = gain_ratio
maximal depth = 20
apply pruning = true
    confidence = 0.25
apply prepruning = true
    minimal gain = 0.1
    minimal leaf size = 2
    minimal size for split = 4
    number of prepruning alternatives = 3
```

модель выдает `9/14` верных предсказаний

Можно отключить pruning и prepruning. Получим `10/14`. Если пробывать различные значения до увидим следуюющий результат: 

maximal depth | result
--------------|-------
3     | 8/14
4-6   | 9/14
7-30  | 10/14

если сейчас включить pruning то результат не изменится. Если менять значение confidence в пределах от 0 до 1 то результат тоже не изменится.

если включить prepruning то результат ухудшится до 9/14. А при некоторых значениях параметров prepruning (minimal leaf size = 3-4) ухудшится до 8/14.

Результата лучше чем 10/14 добиться не удалось.
